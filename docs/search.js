window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "bbrl", "modulename": "bbrl", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.instantiate_class", "modulename": "bbrl", "qualname": "instantiate_class", "type": "function", "doc": "<p></p>\n", "signature": "(arguments)", "funcdef": "def"}, {"fullname": "bbrl.get_class", "modulename": "bbrl", "qualname": "get_class", "type": "function", "doc": "<p></p>\n", "signature": "(arguments)", "funcdef": "def"}, {"fullname": "bbrl.get_arguments", "modulename": "bbrl", "qualname": "get_arguments", "type": "function", "doc": "<p></p>\n", "signature": "(arguments)", "funcdef": "def"}, {"fullname": "bbrl.agents", "modulename": "bbrl.agents", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.agent", "modulename": "bbrl.agents.agent", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.agent.Agent", "modulename": "bbrl.agents.agent", "qualname": "Agent", "type": "class", "doc": "<p>An <code>Agent</code> is a <code>torch.nn.Module</code> that reads and writes into a <code>bbrl.Workspace</code></p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "bbrl.agents.agent.Agent.__init__", "modulename": "bbrl.agents.agent", "qualname": "Agent.__init__", "type": "function", "doc": "<p>To create a new Agent</p>\n\n<p>Args:\n    name ([type], optional): An agent can have a name that will allow to perform operations\n    on agents that are composed into more complex agents.</p>\n", "signature": "(self, name: str = None, verbose=False)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.seed", "modulename": "bbrl.agents.agent", "qualname": "Agent.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, seed: int)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.set_name", "modulename": "bbrl.agents.agent", "qualname": "Agent.set_name", "type": "function", "doc": "<p>Set the name of this agent</p>\n\n<p>Args:\n    n (str): The name</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.get_name", "modulename": "bbrl.agents.agent", "qualname": "Agent.get_name", "type": "function", "doc": "<p>Returns the name of the agent</p>\n\n<p>Returns:\n    str: the name</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.set_trace_file", "modulename": "bbrl.agents.agent", "qualname": "Agent.set_trace_file", "type": "function", "doc": "<p></p>\n", "signature": "(self, filename)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.is_running", "modulename": "bbrl.agents.agent", "qualname": "Agent.is_running", "type": "function", "doc": "<p>Returns True if the agent is currently executing (for remote agents)</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.forward", "modulename": "bbrl.agents.agent", "qualname": "Agent.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.clone", "modulename": "bbrl.agents.agent", "qualname": "Agent.clone", "type": "function", "doc": "<p>Create a clone of the agent</p>\n\n<p>Returns:\n    bbrl.Agent: A clone</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.get", "modulename": "bbrl.agents.agent", "qualname": "Agent.get", "type": "function", "doc": "<p>Returns the value of a particular variable in the agent workspace</p>\n\n<p>Args:\n    index (str or tuple(str,int)): if str, returns the variable workspace[str].\n    If tuple(var_name,t), returns workspace[var_name] at time t</p>\n", "signature": "(self, index)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.get_time_truncated", "modulename": "bbrl.agents.agent", "qualname": "Agent.get_time_truncated", "type": "function", "doc": "<p>Return a variable truncated between from_time and to_time</p>\n", "signature": "(self, var_name, from_time, to_time)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.set", "modulename": "bbrl.agents.agent", "qualname": "Agent.set", "type": "function", "doc": "<p>Write a variable in the workspace</p>\n\n<p>Args:\n    index (str or tuple(str,int)):\n    value (torch.Tensor): the value to write</p>\n", "signature": "(self, index, value)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.get_by_name", "modulename": "bbrl.agents.agent", "qualname": "Agent.get_by_name", "type": "function", "doc": "<p>Returns the list of agents included in this agent that have a particular name.</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.save_model", "modulename": "bbrl.agents.agent", "qualname": "Agent.save_model", "type": "function", "doc": "<p>Save a neural network model into a file</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename</strong>:  the filename, including the path</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(self, filename) -> None", "funcdef": "def"}, {"fullname": "bbrl.agents.agent.Agent.load_model", "modulename": "bbrl.agents.agent", "qualname": "Agent.load_model", "type": "function", "doc": "<p>Load a neural network model from a file</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename</strong>:  the filename, including the path</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>the resulting pytorch network</p>\n</blockquote>\n", "signature": "(self, filename) -> torch.nn.modules.module.Module", "funcdef": "def"}, {"fullname": "bbrl.agents.asynchronous", "modulename": "bbrl.agents.asynchronous", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.asynchronous.f", "modulename": "bbrl.agents.asynchronous", "qualname": "f", "type": "function", "doc": "<p></p>\n", "signature": "(agent, in_queue, out_queue)", "funcdef": "def"}, {"fullname": "bbrl.agents.asynchronous.AsynchronousAgent", "modulename": "bbrl.agents.asynchronous", "qualname": "AsynchronousAgent", "type": "class", "doc": "<p>Implements an agent that is executed aynchronously in another process, and that returns its own workspace</p>\n\n<p>Usage is:</p>\n\n<ul>\n<li>agent(workspace)</li>\n<li>while agent.is_running():</li>\n<li>.....</li>\n<li>workspace=agent.get_workspace()</li>\n</ul>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.asynchronous.AsynchronousAgent.__init__", "modulename": "bbrl.agents.asynchronous", "qualname": "AsynchronousAgent.__init__", "type": "function", "doc": "<p>To create a new Agent</p>\n\n<p>Args:\n    name ([type], optional): An agent can have a name that will allow to perform operations\n    on agents that are composed into more complex agents.</p>\n", "signature": "(self, agent, verbose=False)", "funcdef": "def"}, {"fullname": "bbrl.agents.asynchronous.AsynchronousAgent.is_running", "modulename": "bbrl.agents.asynchronous", "qualname": "AsynchronousAgent.is_running", "type": "function", "doc": "<p>Is the agent still running ?</p>\n\n<p>Returns:\n    [bool]: True is the agent is running</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.asynchronous.AsynchronousAgent.get_workspace", "modulename": "bbrl.agents.asynchronous", "qualname": "AsynchronousAgent.get_workspace", "type": "function", "doc": "<p>Returns the built workspace is the agent has stopped its execution</p>\n\n<p>Returns:\n    [bbrl.Workspace]: The built workspace</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.asynchronous.AsynchronousAgent.close", "modulename": "bbrl.agents.asynchronous", "qualname": "AsynchronousAgent.close", "type": "function", "doc": "<p>Close the agent and kills the corresponding process</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader", "modulename": "bbrl.agents.dataloader", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.dataloader.ShuffledDatasetAgent", "modulename": "bbrl.agents.dataloader", "qualname": "ShuffledDatasetAgent", "type": "class", "doc": "<p>An agent that read a dataset in a shuffle order, in an infinite way.</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.dataloader.ShuffledDatasetAgent.__init__", "modulename": "bbrl.agents.dataloader", "qualname": "ShuffledDatasetAgent.__init__", "type": "function", "doc": "<p>Create the agent</p>\n\n<p>Args:\n    dataset ([torch.utils.data.Dataset]): the Dataset\n    batch_size ([int]): The number of datapoints to write at each call\n    output_names (tuple, optional): The name of the variables. Defaults to (\"x\", \"y\").</p>\n", "signature": "(self, dataset, batch_size, output_names=('x', 'y'))", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.ShuffledDatasetAgent.seed", "modulename": "bbrl.agents.dataloader", "qualname": "ShuffledDatasetAgent.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, seed=None)", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.ShuffledDatasetAgent.forward", "modulename": "bbrl.agents.dataloader", "qualname": "ShuffledDatasetAgent.forward", "type": "function", "doc": "<p>Write a batch of data at timestep==0 in the workspace</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.DataLoaderAgent", "modulename": "bbrl.agents.dataloader", "qualname": "DataLoaderAgent", "type": "class", "doc": "<p>An agent based on a DataLoader that read a single dataset\nUsage is: agent.forward(), then one has to check if agent.finished() is True or Not. If True, then no data have been written in the workspace since the reading of the daaset is terminated</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.dataloader.DataLoaderAgent.__init__", "modulename": "bbrl.agents.dataloader", "qualname": "DataLoaderAgent.__init__", "type": "function", "doc": "<p>Create the agent based on a dataloader</p>\n\n<p>Args:\n    dataloader ([DataLader]): The underlying pytoch daaloader object\n    output_names (tuple, optional): Names of the variable to write in the workspace. Defaults to (\"x\", \"y\").</p>\n", "signature": "(self, dataloader, output_names=('x', 'y'))", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.DataLoaderAgent.reset", "modulename": "bbrl.agents.dataloader", "qualname": "DataLoaderAgent.reset", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.DataLoaderAgent.finished", "modulename": "bbrl.agents.dataloader", "qualname": "DataLoaderAgent.finished", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.dataloader.DataLoaderAgent.forward", "modulename": "bbrl.agents.dataloader", "qualname": "DataLoaderAgent.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma", "modulename": "bbrl.agents.gyma", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.gyma.GymAgent", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent", "type": "class", "doc": "<p>Create an Agent from a gym environment</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.gyma.GymAgent.__init__", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    seed (int): the seed used to initialize the environment\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.set_obs", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.set_obs", "type": "function", "doc": "<p></p>\n", "signature": "(self, observations, t)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.forward", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.forward", "type": "function", "doc": "<p>Do one step by reading the <code>action</code> at t-1\nIf t==0, environments are reset\nIf save_render is True, then the output of env.render(mode=\"image\") is written as env/rendering</p>\n", "signature": "(self, t=0, save_render=False, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.is_continuous_action", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.is_continuous_action", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.is_discrete_action", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.is_discrete_action", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.is_continuous_state", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.is_continuous_state", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.is_discrete_state", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.is_discrete_state", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.GymAgent.get_obs_and_actions_sizes", "modulename": "bbrl.agents.gyma", "qualname": "GymAgent.get_obs_and_actions_sizes", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.AutoResetGymAgent", "modulename": "bbrl.agents.gyma", "qualname": "AutoResetGymAgent", "type": "class", "doc": "<p>The same as GymAgent, but with an automatic reset when done is True</p>\n", "bases": "GymAgent"}, {"fullname": "bbrl.agents.gyma.AutoResetGymAgent.__init__", "modulename": "bbrl.agents.gyma", "qualname": "AutoResetGymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment with Autoreset</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    seed (int): the seed used to initialize the environment\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.AutoResetGymAgent.forward", "modulename": "bbrl.agents.gyma", "qualname": "AutoResetGymAgent.forward", "type": "function", "doc": "<p>Perform one step by reading the <code>action</code></p>\n", "signature": "(self, t=0, save_render=False, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.gyma.NoAutoResetGymAgent", "modulename": "bbrl.agents.gyma", "qualname": "NoAutoResetGymAgent", "type": "class", "doc": "<p>The same as GymAgent, named to make sure it is not AutoReset</p>\n", "bases": "GymAgent"}, {"fullname": "bbrl.agents.gyma.NoAutoResetGymAgent.__init__", "modulename": "bbrl.agents.gyma", "qualname": "NoAutoResetGymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    seed (int): the seed used to initialize the environment\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb", "modulename": "bbrl.agents.gymb", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.gymb.GymAgent", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent", "type": "class", "doc": "<p>Create an Agent from a gym environment</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.gymb.GymAgent.__init__", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    seed (int): the seed used to initialize the environment\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.set_obs", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.set_obs", "type": "function", "doc": "<p></p>\n", "signature": "(self, observations, t)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.set_next_obs", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.set_next_obs", "type": "function", "doc": "<p></p>\n", "signature": "(self, observations, t)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.set_reward", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.set_reward", "type": "function", "doc": "<p></p>\n", "signature": "(self, rewards, t)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.forward", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.forward", "type": "function", "doc": "<p>Do one step by reading the <code>action</code> at t-1\nIf t==0, environments are reset\nIf save_render is True, then the output of env.render(mode=\"image\") is written as env/rendering</p>\n", "signature": "(self, t=0, save_render=False, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.is_continuous_action", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.is_continuous_action", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.is_discrete_action", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.is_discrete_action", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.is_continuous_state", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.is_continuous_state", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.is_discrete_state", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.is_discrete_state", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.GymAgent.get_obs_and_actions_sizes", "modulename": "bbrl.agents.gymb", "qualname": "GymAgent.get_obs_and_actions_sizes", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.AutoResetGymAgent", "modulename": "bbrl.agents.gymb", "qualname": "AutoResetGymAgent", "type": "class", "doc": "<p>The same as GymAgent, but with an automatic reset when done is True</p>\n", "bases": "GymAgent"}, {"fullname": "bbrl.agents.gymb.AutoResetGymAgent.__init__", "modulename": "bbrl.agents.gymb", "qualname": "AutoResetGymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment  with Autoreset</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    use_seed (bool, optional): [If True, then the seed is chained to the environments,\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.AutoResetGymAgent.forward", "modulename": "bbrl.agents.gymb", "qualname": "AutoResetGymAgent.forward", "type": "function", "doc": "<p>Perform one step by reading the <code>action</code></p>\n", "signature": "(self, t=0, save_render=False, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.gymb.NoAutoResetGymAgent", "modulename": "bbrl.agents.gymb", "qualname": "NoAutoResetGymAgent", "type": "class", "doc": "<p>The same as GymAgent, named to make sure it is not AutoReset</p>\n", "bases": "GymAgent"}, {"fullname": "bbrl.agents.gymb.NoAutoResetGymAgent.__init__", "modulename": "bbrl.agents.gymb", "qualname": "NoAutoResetGymAgent.__init__", "type": "function", "doc": "<p>Create an agent from a Gym environment</p>\n\n<p>Args:\n    make_env_fn ([function that returns a gym.Env]): The function to create a single gym environments\n    make_env_args (dict): The arguments of the function that creates a gym.Env\n    n_envs ([int]): The number of environments to create.\n    action_string (str, optional): [the name of the action variable in the workspace]. Defaults to \"action\".\n    output (str, optional): [the output prefix of the environment]. Defaults to \"env/\".\n    seed (int): the seed used to initialize the environment\n    and each environment will have its own seed]. Defaults to True.</p>\n", "signature": "(\n    self,\n    make_env_fn=None,\n    make_env_args={},\n    n_envs=None,\n    seed=None,\n    action_string='action',\n    output='env/'\n)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote", "modulename": "bbrl.agents.remote", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.remote.f", "modulename": "bbrl.agents.remote", "qualname": "f", "type": "function", "doc": "<p>The function that is executed in a single process</p>\n", "signature": "(agent, in_queue, out_queue, seed, verbose)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent", "type": "class", "doc": "<p>It corresponds to an agent that is executed in another process</p>\n\n<p>Args:\n    Agent ([bbrl.Agent]): the agent ot execute in another process</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.remote.RemoteAgent.__init__", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.__init__", "type": "function", "doc": "<p>To create a new Agent</p>\n\n<p>Args:\n    name ([type], optional): An agent can have a name that will allow to perform operations\n    on agents that are composed into more complex agents.</p>\n", "signature": "(self, agent, name=None, verbose=False)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.get_by_name", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.get_by_name", "type": "function", "doc": "<p>Returns the list of agents included in this agent that have a particular name.</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.forward", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.train", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.train", "type": "function", "doc": "<p>Sets the module in training mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>Args:\n    mode (bool): whether to set training mode (<code>True</code>) or evaluation\n                 mode (<code>False</code>). Default: <code>True</code>.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "(self, f=True)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.eval", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.seed", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, _seed)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.is_running", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.is_running", "type": "function", "doc": "<p>Returns True if the agent is currently executing (for remote agents)</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.RemoteAgent.close", "modulename": "bbrl.agents.remote", "qualname": "RemoteAgent.close", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent", "type": "class", "doc": "<p>Multiple agents executed in different processes. Use the <code>NRemoteAgent.create</code> function to create such an agent</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.__init__", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.__init__", "type": "function", "doc": "<p>To create a new Agent</p>\n\n<p>Args:\n    name ([type], optional): An agent can have a name that will allow to perform operations\n    on agents that are composed into more complex agents.</p>\n", "signature": "(self, agents, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.get_by_name", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.get_by_name", "type": "function", "doc": "<p>Returns the list of agents included in this agent that have a particular name.</p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.create", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.create", "type": "function", "doc": "<p>Returns a NRemote agent with num_processes copies of agent in different processes\nAlso returns the specific workspace to use with such an agent</p>\n\n<p>Args:\n    agent ([bbrl.Agent]): The agent to execute in multiple processes\n    num_processes (int, optional): Number of processes to create. If 0, then no processes are created (for debugging). Defaults to 0.\n    time_size ([type], optional): If specified, it forces the created Workspace to have this particular time_size. Defaults to None.</p>\n\n<p>Returns:\n    [bbrl.Agent,bbrl.SharedWorkspace]: The NRemoteAgent and the corresponding workspace</p>\n", "signature": "(agent, num_processes=0, time_size=None, **extra_kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.seed", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, seed, inc=1)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.is_running", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.is_running", "type": "function", "doc": "<p>Returns True if the agent is currently executing (for remote agents)</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.train", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.train", "type": "function", "doc": "<p>Sets the module in training mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>Args:\n    mode (bool): whether to set training mode (<code>True</code>) or evaluation\n                 mode (<code>False</code>). Default: <code>True</code>.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "(self, f=True)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.eval", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.remote.NRemoteAgent.close", "modulename": "bbrl.agents.remote", "qualname": "NRemoteAgent.close", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils", "modulename": "bbrl.agents.utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.agents.utils.Agents", "modulename": "bbrl.agents.utils", "qualname": "Agents", "type": "class", "doc": "<p>An agent that contains multiple agents that will be executed sequentially</p>\n\n<p>Args:\n    Agent ([bbrl.Agent]): The agents</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.utils.Agents.__init__", "modulename": "bbrl.agents.utils", "qualname": "Agents.__init__", "type": "function", "doc": "<p>Creates the agent from multiple agents</p>\n\n<p>Args:\n    name ([str], optional): [name of the resulting agent]. Defaults to None.</p>\n", "signature": "(self, *agents, name=None)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.Agents.forward", "modulename": "bbrl.agents.utils", "qualname": "Agents.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.Agents.seed", "modulename": "bbrl.agents.utils", "qualname": "Agents.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, seed)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.Agents.get_by_name", "modulename": "bbrl.agents.utils", "qualname": "Agents.get_by_name", "type": "function", "doc": "<p>Returns the list of agents included in this agent that have a particular name.</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.TemporalAgent", "modulename": "bbrl.agents.utils", "qualname": "TemporalAgent", "type": "class", "doc": "<p>Execute one Agent over multiple timesteps</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.utils.TemporalAgent.__init__", "modulename": "bbrl.agents.utils", "qualname": "TemporalAgent.__init__", "type": "function", "doc": "<p>The agent to transform to a temporal agent</p>\n\n<p>Args:\n    agent ([bbrl.Agent]): The agent to encapsulate\n    name ([str], optional): Name of the agent</p>\n", "signature": "(self, agent, name=None)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.TemporalAgent.forward", "modulename": "bbrl.agents.utils", "qualname": "TemporalAgent.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.TemporalAgent.seed", "modulename": "bbrl.agents.utils", "qualname": "TemporalAgent.seed", "type": "function", "doc": "<p>Provide a seed to this agent. Useful is the agent is stochastic.</p>\n\n<p>Args:\n    seed (str): [description]</p>\n", "signature": "(self, seed)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.TemporalAgent.get_by_name", "modulename": "bbrl.agents.utils", "qualname": "TemporalAgent.get_by_name", "type": "function", "doc": "<p>Returns the list of agents included in this agent that have a particular name.</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.CopyTAgent", "modulename": "bbrl.agents.utils", "qualname": "CopyTAgent", "type": "class", "doc": "<p>An agent that copies a variable</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.utils.CopyTAgent.__init__", "modulename": "bbrl.agents.utils", "qualname": "CopyTAgent.__init__", "type": "function", "doc": "<p>Args:\ninput_name ([str]): The variable to copy from\noutput_name ([str]): The variable to copy to\ndetach ([bool]): copy with detach if True</p>\n", "signature": "(self, input_name, output_name, detach=False, name=None)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.CopyTAgent.forward", "modulename": "bbrl.agents.utils", "qualname": "CopyTAgent.forward", "type": "function", "doc": "<p>Args:\n    t ([type], optional): if not None, copy at time t. Defaults to None.</p>\n", "signature": "(self, t=None, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.PrintAgent", "modulename": "bbrl.agents.utils", "qualname": "PrintAgent", "type": "class", "doc": "<p>An agent to generate print in the console (mainly for debugging)\nIt can be passed a list of strings corresponding to the variables to print\nor if nothing is passed, it prints all the existing variables in the workspace</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.utils.PrintAgent.__init__", "modulename": "bbrl.agents.utils", "qualname": "PrintAgent.__init__", "type": "function", "doc": "<p>Args:\n    names ([str], optional): The variables to print</p>\n", "signature": "(self, *names, name=None)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.PrintAgent.reset", "modulename": "bbrl.agents.utils", "qualname": "PrintAgent.reset", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.PrintAgent.forward", "modulename": "bbrl.agents.utils", "qualname": "PrintAgent.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, t, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.EpisodesDone", "modulename": "bbrl.agents.utils", "qualname": "EpisodesDone", "type": "class", "doc": "<p>If done is encountered at time t, then done=True for all timeteps t'>=t\nIt allows to simulate a single episode agent based on an autoreset agent</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.agents.utils.EpisodesDone.__init__", "modulename": "bbrl.agents.utils", "qualname": "EpisodesDone.__init__", "type": "function", "doc": "<p>To create a new Agent</p>\n\n<p>Args:\n    name ([type], optional): An agent can have a name that will allow to perform operations\n    on agents that are composed into more complex agents.</p>\n", "signature": "(self, in_var='env/done', out_var='env/done')", "funcdef": "def"}, {"fullname": "bbrl.agents.utils.EpisodesDone.forward", "modulename": "bbrl.agents.utils", "qualname": "EpisodesDone.forward", "type": "function", "doc": "<p>The generic function to override when defining a new agent</p>\n", "signature": "(self, t, **kwargs)", "funcdef": "def"}, {"fullname": "bbrl.utils", "modulename": "bbrl.utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.chrono", "modulename": "bbrl.utils.chrono", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.chrono.Chrono", "modulename": "bbrl.utils.chrono", "qualname": "Chrono", "type": "class", "doc": "<p>Description: Class to display time spent in human format rather than seconds</p>\n"}, {"fullname": "bbrl.utils.chrono.Chrono.__init__", "modulename": "bbrl.utils.chrono", "qualname": "Chrono.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.chrono.Chrono.stop", "modulename": "bbrl.utils.chrono", "qualname": "Chrono.stop", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.functional", "modulename": "bbrl.utils.functional", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.functional.cumulated_reward", "modulename": "bbrl.utils.functional", "qualname": "cumulated_reward", "type": "function", "doc": "<p></p>\n", "signature": "(reward, done)", "funcdef": "def"}, {"fullname": "bbrl.utils.functional.temporal_difference", "modulename": "bbrl.utils.functional", "qualname": "temporal_difference", "type": "function", "doc": "<p></p>\n", "signature": "(critic, reward, must_bootstrap, discount_factor)", "funcdef": "def"}, {"fullname": "bbrl.utils.functional.doubleqlearning_temporal_difference", "modulename": "bbrl.utils.functional", "qualname": "doubleqlearning_temporal_difference", "type": "function", "doc": "<p></p>\n", "signature": "(q, action, q_target, reward, must_bootstrap, discount_factor)", "funcdef": "def"}, {"fullname": "bbrl.utils.functional.gae", "modulename": "bbrl.utils.functional", "qualname": "gae", "type": "function", "doc": "<p></p>\n", "signature": "(critic, reward, must_bootstrap, discount_factor, gae_coef)", "funcdef": "def"}, {"fullname": "bbrl.utils.functional.compute_reinforce_loss", "modulename": "bbrl.utils.functional", "qualname": "compute_reinforce_loss", "type": "function", "doc": "<p></p>\n", "signature": "(\n    reward,\n    action_probabilities,\n    baseline,\n    action,\n    done,\n    discount_factor\n)", "funcdef": "def"}, {"fullname": "bbrl.utils.functionalb", "modulename": "bbrl.utils.functionalb", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.functionalb.cumulated_reward", "modulename": "bbrl.utils.functionalb", "qualname": "cumulated_reward", "type": "function", "doc": "<p></p>\n", "signature": "(reward, done)", "funcdef": "def"}, {"fullname": "bbrl.utils.functionalb.temporal_difference", "modulename": "bbrl.utils.functionalb", "qualname": "temporal_difference", "type": "function", "doc": "<p></p>\n", "signature": "(critic, reward, must_bootstrap, discount_factor)", "funcdef": "def"}, {"fullname": "bbrl.utils.functionalb.doubleqlearning_temporal_difference", "modulename": "bbrl.utils.functionalb", "qualname": "doubleqlearning_temporal_difference", "type": "function", "doc": "<p></p>\n", "signature": "(q, action, q_target, reward, must_bootstrap, discount_factor)", "funcdef": "def"}, {"fullname": "bbrl.utils.functionalb.gae", "modulename": "bbrl.utils.functionalb", "qualname": "gae", "type": "function", "doc": "<p></p>\n", "signature": "(critic, reward, must_bootstrap, discount_factor, gae_coef)", "funcdef": "def"}, {"fullname": "bbrl.utils.functionalb.compute_reinforce_loss", "modulename": "bbrl.utils.functionalb", "qualname": "compute_reinforce_loss", "type": "function", "doc": "<p></p>\n", "signature": "(\n    reward,\n    action_probabilities,\n    baseline,\n    action,\n    done,\n    discount_factor\n)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger", "modulename": "bbrl.utils.logger", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger", "type": "class", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.__init__", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, prefix, logger)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.add_images", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.add_images", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.add_figure", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.add_figure", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.add_scalar", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.add_scalar", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.add_video", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.add_video", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, value, iteration, fps=10)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.message", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.message", "type": "function", "doc": "<p></p>\n", "signature": "(self, msg, from_name='')", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.debug", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.debug", "type": "function", "doc": "<p></p>\n", "signature": "(self, msg, from_name='')", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.get_logger", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.get_logger", "type": "function", "doc": "<p></p>\n", "signature": "(self, prefix)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFPrefixLogger.close", "modulename": "bbrl.utils.logger", "qualname": "TFPrefixLogger.close", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger", "modulename": "bbrl.utils.logger", "qualname": "TFLogger", "type": "class", "doc": "<p>A logger that stores informations both in tensorboard and CSV formats</p>\n", "bases": "torch.utils.tensorboard.writer.SummaryWriter"}, {"fullname": "bbrl.utils.logger.TFLogger.__init__", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.__init__", "type": "function", "doc": "<p>Creates a <code>SummaryWriter</code> that will write out events and summaries\nto the event file.</p>\n\n<p>Args:\n    log_dir (string): Save directory location. Default is\n      runs/<strong>CURRENT_DATETIME_HOSTNAME</strong>, which changes after each run.\n      Use hierarchical folder structure to compare\n      between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.\n      for each new experiment to compare across them.\n    comment (string): Comment log_dir suffix appended to the default\n      <code>log_dir</code>. If <code>log_dir</code> is assigned, this argument has no effect.\n    purge_step (int):\n      When logging crashes at step \\( T+X \\) and restarts at step \\( T \\),\n      any events whose global_step larger or equal to \\( T \\) will be\n      purged and hidden from TensorBoard.\n      Note that crashed and resumed experiments should have the same <code>log_dir</code>.\n    max_queue (int): Size of the queue for pending events and\n      summaries before one of the 'add' calls forces a flush to disk.\n      Default is ten items.\n    flush_secs (int): How often, in seconds, to flush the\n      pending events and summaries to disk. Default is every two minutes.\n    filename_suffix (string): Suffix added to all event filenames in\n      the log_dir directory. More details on filename construction in\n      tensorboard.summary.writer.event_file_writer.EventFileWriter.</p>\n\n<p>Examples::</p>\n\n<pre><code>from torch.utils.tensorboard import SummaryWriter\n\n# create a summary writer with automatically generated folder name.\nwriter = SummaryWriter()\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n\n# create a summary writer using the specified folder name.\nwriter = SummaryWriter(\"my_experiment\")\n# folder location: my_experiment\n\n# create a summary writer with comment appended.\nwriter = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n</code></pre>\n", "signature": "(\n    self,\n    log_dir=None,\n    hps={},\n    cache_size=10000,\n    every_n_seconds=None,\n    modulo=1,\n    verbose=False,\n    use_zip=True,\n    save_tensorboard=True\n)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.save_hps", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.save_hps", "type": "function", "doc": "<p></p>\n", "signature": "(self, hps, verbose=True)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.get_logger", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.get_logger", "type": "function", "doc": "<p></p>\n", "signature": "(self, prefix)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.message", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.message", "type": "function", "doc": "<p></p>\n", "signature": "(self, msg, from_name='')", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.debug", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.debug", "type": "function", "doc": "<p></p>\n", "signature": "(self, msg, from_name='')", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.add_images", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.add_images", "type": "function", "doc": "<p>Add batched image data to summary.</p>\n\n<p>Note that this requires the <code>pillow</code> package.</p>\n\n<p>Args:\n    tag (string): Data identifier\n    img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data\n    global_step (int): Global step value to record\n    walltime (float): Optional override default walltime (time.time())\n      seconds after epoch of event\n    dataformats (string): Image data format specification of the form\n      NCHW, NHWC, CHW, HWC, HW, WH, etc.\nShape:\n    img_tensor: Default is \\( (N, 3, H, W) \\). If <code>dataformats</code> is specified, other shape will be\n    accepted. e.g. NCHW or NHWC.</p>\n\n<p>Examples::</p>\n\n<pre><code>from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nimg_batch = np.zeros((16, 3, 100, 100))\nfor i in range(16):\n    img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n    img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n\nwriter = SummaryWriter()\nwriter.add_images('my_image_batch', img_batch, 0)\nwriter.close()\n</code></pre>\n\n<p>Expected result:</p>\n\n<p>.. image:: _static/img/tensorboard/add_images.png\n   :scale: 30 %</p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.add_figure", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.add_figure", "type": "function", "doc": "<p>Render matplotlib figure into an image and add it to summary.</p>\n\n<p>Note that this requires the <code>matplotlib</code> package.</p>\n\n<p>Args:\n    tag (string): Data identifier\n    figure (matplotlib.pyplot.figure) or list of figures: Figure or a list of figures\n    global_step (int): Global step value to record\n    close (bool): Flag to automatically close the figure\n    walltime (float): Optional override default walltime (time.time())\n      seconds after epoch of event</p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.add_scalar", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.add_scalar", "type": "function", "doc": "<p>Add scalar data to summary.</p>\n\n<p>Args:\n    tag (string): Data identifier\n    scalar_value (float or string/blobname): Value to save\n    global_step (int): Global step value to record\n    walltime (float): Optional override default walltime (time.time())\n      with seconds after epoch of event\n    new_style (boolean): Whether to use new style (tensor field) or old\n      style (simple_value field). New style could lead to faster data loading.\nExamples::</p>\n\n<pre><code>from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('y=2x', i * 2, i)\nwriter.close()\n</code></pre>\n\n<p>Expected result:</p>\n\n<p>.. image:: _static/img/tensorboard/add_scalar.png\n   :scale: 50 %</p>\n", "signature": "(self, name, value, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.add_video", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.add_video", "type": "function", "doc": "<p>Add video data to summary.</p>\n\n<p>Note that this requires the <code>moviepy</code> package.</p>\n\n<p>Args:\n    tag (string): Data identifier\n    vid_tensor (torch.Tensor): Video data\n    global_step (int): Global step value to record\n    fps (float or int): Frames per second\n    walltime (float): Optional override default walltime (time.time())\n      seconds after epoch of event\nShape:\n    vid_tensor: \\( (N, T, C, H, W) \\). The values should lie in [0, 255] for type <code>uint8</code> or [0, 1] for type <code>float</code>.</p>\n", "signature": "(self, name, value, iteration, fps=10)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.TFLogger.close", "modulename": "bbrl.utils.logger", "qualname": "TFLogger.close", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log", "modulename": "bbrl.utils.logger", "qualname": "Log", "type": "class", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.logger.Log.__init__", "modulename": "bbrl.utils.logger", "qualname": "Log.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, hps, values)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.to_xy", "modulename": "bbrl.utils.logger", "qualname": "Log.to_xy", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.to_dataframe", "modulename": "bbrl.utils.logger", "qualname": "Log.to_dataframe", "type": "function", "doc": "<p></p>\n", "signature": "(self, with_hps=False)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.get_at", "modulename": "bbrl.utils.logger", "qualname": "Log.get_at", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, iteration)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.get", "modulename": "bbrl.utils.logger", "qualname": "Log.get", "type": "function", "doc": "<p></p>\n", "signature": "(self, name, keep_none=False)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.replace_none_", "modulename": "bbrl.utils.logger", "qualname": "Log.replace_none_", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.max", "modulename": "bbrl.utils.logger", "qualname": "Log.max", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.min", "modulename": "bbrl.utils.logger", "qualname": "Log.min", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.argmin", "modulename": "bbrl.utils.logger", "qualname": "Log.argmin", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Log.argmax", "modulename": "bbrl.utils.logger", "qualname": "Log.argmax", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs", "modulename": "bbrl.utils.logger", "qualname": "Logs", "type": "class", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.logger.Logs.__init__", "modulename": "bbrl.utils.logger", "qualname": "Logs.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.add", "modulename": "bbrl.utils.logger", "qualname": "Logs.add", "type": "function", "doc": "<p></p>\n", "signature": "(self, logs)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.max", "modulename": "bbrl.utils.logger", "qualname": "Logs.max", "type": "function", "doc": "<p></p>\n", "signature": "(self, function)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.columns", "modulename": "bbrl.utils.logger", "qualname": "Logs.columns", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.hps", "modulename": "bbrl.utils.logger", "qualname": "Logs.hps", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.size", "modulename": "bbrl.utils.logger", "qualname": "Logs.size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.filter", "modulename": "bbrl.utils.logger", "qualname": "Logs.filter", "type": "function", "doc": "<p></p>\n", "signature": "(self, hp_name, test_fn)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.unique_hps", "modulename": "bbrl.utils.logger", "qualname": "Logs.unique_hps", "type": "function", "doc": "<p></p>\n", "signature": "(self, name)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.Logs.to_dataframe", "modulename": "bbrl.utils.logger", "qualname": "Logs.to_dataframe", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.flattify", "modulename": "bbrl.utils.logger", "qualname": "flattify", "type": "function", "doc": "<p></p>\n", "signature": "(d)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.read_log", "modulename": "bbrl.utils.logger", "qualname": "read_log", "type": "function", "doc": "<p></p>\n", "signature": "(directory, use_bz2=True, debug=False)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.get_directories", "modulename": "bbrl.utils.logger", "qualname": "get_directories", "type": "function", "doc": "<p></p>\n", "signature": "(directory, use_bz2=True)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.read_directories", "modulename": "bbrl.utils.logger", "qualname": "read_directories", "type": "function", "doc": "<p></p>\n", "signature": "(directories, use_bz2=True)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.read_directory", "modulename": "bbrl.utils.logger", "qualname": "read_directory", "type": "function", "doc": "<p></p>\n", "signature": "(directory, use_bz2=True)", "funcdef": "def"}, {"fullname": "bbrl.utils.logger.plot_dataframe", "modulename": "bbrl.utils.logger", "qualname": "plot_dataframe", "type": "function", "doc": "<p></p>\n", "signature": "(\n    df,\n    y,\n    x='iteration',\n    hue=None,\n    style=None,\n    row=None,\n    col=None,\n    kind='line'\n)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer", "modulename": "bbrl.utils.replay_buffer", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer", "type": "class", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.__init__", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, max_size, device=device(type='cpu'))", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.init_workspace", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.init_workspace", "type": "function", "doc": "<p>Create an array to stores workspace based on the given all_tensors keys.\nshape of stores tensors : [key] =&gt; [self.max_size][time_size][key_dim]\nMakes a copy of the input content</p>\n", "signature": "(self, all_tensors)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.put", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.put", "type": "function", "doc": "<p>Add a the content of a workspace to the replay buffer.\nThe given workspace must have keys of shape : [time_size][batch_size][key_dim]</p>\n", "signature": "(self, workspace)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.size", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.print_obs", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.print_obs", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.get_shuffled", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.get_shuffled", "type": "function", "doc": "<p></p>\n", "signature": "(self, batch_size)", "funcdef": "def"}, {"fullname": "bbrl.utils.replay_buffer.ReplayBuffer.to", "modulename": "bbrl.utils.replay_buffer", "qualname": "ReplayBuffer.to", "type": "function", "doc": "<p></p>\n", "signature": "(self, device)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils", "modulename": "bbrl.utils.utils", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.utils.utils.get_env_dimensions", "modulename": "bbrl.utils.utils", "qualname": "get_env_dimensions", "type": "function", "doc": "<p></p>\n", "signature": "(env) -> tuple", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.make_gym_env", "modulename": "bbrl.utils.utils", "qualname": "make_gym_env", "type": "function", "doc": "<p></p>\n", "signature": "(max_episode_steps, env_name)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.soft_param_update", "modulename": "bbrl.utils.utils", "qualname": "soft_param_update", "type": "function", "doc": "<p></p>\n", "signature": "(network_to_update, network, rho)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.key_path_in_dict", "modulename": "bbrl.utils.utils", "qualname": "key_path_in_dict", "type": "function", "doc": "<p>Check if a sequences of keys exists in a nested dict</p>\n", "signature": "(nested_dict: dict, key_path: str)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.set_value_with_key_path", "modulename": "bbrl.utils.utils", "qualname": "set_value_with_key_path", "type": "function", "doc": "<p></p>\n", "signature": "(nested_dict: omegaconf.dictconfig.DictConfig, key_path: str, value)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.vector_to_parameters", "modulename": "bbrl.utils.utils", "qualname": "vector_to_parameters", "type": "function", "doc": "<p>Convert one vector to the parameters</p>\n\n<p>Args:\n    vec (Tensor): a single vector represents the parameters of a model.\n    parameters (Iterable[Tensor]): an iterator of Tensors that are the\n        parameters of a model.</p>\n", "signature": "(vec: torch.Tensor, parameters) -> None", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteParamAgent", "modulename": "bbrl.utils.utils", "qualname": "nRemoteParamAgent", "type": "class", "doc": "<p>Class that allows to evaluate N (different) individuals with m processes\nThe user have to provide:\n   1/ the aquisition agent list or template\n   2/ list of parameters for each of the individual of the pop\n   3/ the function that apply the parameters to the acquisition agent\nThis implementation is based on the  Asynchronous agents\n(I think another implementation could use the NRemote agent\nmaybe by slicing the shared workspace to separate the experiences\ncollected by each individual)</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.utils.utils.nRemoteParamAgent.__init__", "modulename": "bbrl.utils.utils", "qualname": "nRemoteParamAgent.__init__", "type": "function", "doc": "<p>Implements a list of agent which are executed aynchronously in another process.\nEach agent can be parametrized by specific parameters and will returns it's own workspace.\nacq_agent : an instance of the agent that will be runned over each processes\nn_process :\napply_params : a function f(acq_agent, param) =&gt; acq_agent\n               Allow to update each of the agent with a specific set of parameters.</p>\n", "signature": "(\n    self,\n    acq_agent: bbrl.agents.agent.Agent,\n    n_process: int,\n    name: str = ''\n)", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteParamAgent.get_workspaces", "modulename": "bbrl.utils.utils", "qualname": "nRemoteParamAgent.get_workspaces", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> List[bbrl.workspace.Workspace]", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteParamAgent.close", "modulename": "bbrl.utils.utils", "qualname": "nRemoteParamAgent.close", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> None", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteDistinctAgents", "modulename": "bbrl.utils.utils", "qualname": "nRemoteDistinctAgents", "type": "class", "doc": "<p>Class that allows to evaluate N (different) individuals with m processes\nBasic usage :\nremote = nRemoteDistinctAgents(n_process)\nremote(acq_agent_list,)\nThe user have to provide:\n    1/ a list of acqusition_agent that will be copied to remotes\nThis implementation is based on the  Asynchronous agents\n(i think another implementation could use the Nremote agent\nmaybe by slicing the shared workspace to separate the experiences\ncollected by each individual)</p>\n", "bases": "bbrl.agents.agent.Agent"}, {"fullname": "bbrl.utils.utils.nRemoteDistinctAgents.__init__", "modulename": "bbrl.utils.utils", "qualname": "nRemoteDistinctAgents.__init__", "type": "function", "doc": "<p>Implements a list of agent which are executed aynchronously in another process.\nEach agent can be parametrized by specific parameters and will returns it's own\nworkspace.\nacq_agent : an instance of the agent that will be runned over each processes\nn_process :\napply_params : a function f(acq_agent, param) =&gt; acq_agent\n               Allow to update each of the agent with a specific set of parameters.</p>\n", "signature": "(self, n_process: int, name: str = '')", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteDistinctAgents.get_workspaces", "modulename": "bbrl.utils.utils", "qualname": "nRemoteDistinctAgents.get_workspaces", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> List[bbrl.workspace.Workspace]", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.nRemoteDistinctAgents.close", "modulename": "bbrl.utils.utils", "qualname": "nRemoteDistinctAgents.close", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> None", "funcdef": "def"}, {"fullname": "bbrl.utils.utils.is_vec_of_ones", "modulename": "bbrl.utils.utils", "qualname": "is_vec_of_ones", "type": "function", "doc": "<p></p>\n", "signature": "(vec) -> bool", "funcdef": "def"}, {"fullname": "bbrl.visu", "modulename": "bbrl.visu", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.visu.common", "modulename": "bbrl.visu.common", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.visu.common.final_show", "modulename": "bbrl.visu.common", "qualname": "final_show", "type": "function", "doc": "<p>Finalize all plots, adding labels and putting the corresponding file in the\nspecified directory</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>save_figure</strong>:  boolean stating whether the figure should be saved</li>\n<li><strong>plot</strong>:  whether the plot should be shown interactively</li>\n<li><strong>figure_name</strong>:  the name of the file where to save the figure</li>\n<li><strong>x_label</strong>:  label on the x axis</li>\n<li><strong>y_label</strong>:  label on the y axis</li>\n<li><strong>title</strong>:  title of the figure</li>\n<li><strong>directory</strong>:  the path where to save the picture</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(save_figure, plot, directory, figure_name, x_label, y_label, title)", "funcdef": "def"}, {"fullname": "bbrl.visu.svpg_histograms", "modulename": "bbrl.visu.svpg_histograms", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.visu.svpg_histograms.plot_histograms", "modulename": "bbrl.visu.svpg_histograms", "qualname": "plot_histograms", "type": "function", "doc": "<p></p>\n", "signature": "(\n    rewards_list,\n    labels,\n    colors,\n    title,\n    directory,\n    plot=True,\n    save_figure=True\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics", "modulename": "bbrl.visu.visu_critics", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.visu.visu_critics.plot_critic", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_critic", "type": "function", "doc": "<p></p>\n", "signature": "(agent, env, directory, env_name, best_reward, plot=False) -> None", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_pendulum_critic_v", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_pendulum_critic_v", "type": "function", "doc": "<p>Plot a critic for the Pendulum environment</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the evaluation environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file to save the figure</li>\n<li><strong>save_figure</strong>:  whether the figure should be saved</li>\n<li><strong>stochastic</strong>:  whether we plot the deterministic or stochastic version</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    stochastic=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_cartpole_critic_v", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_cartpole_critic_v", "type": "function", "doc": "<p>Visualization of the critic in a N-dimensional state space\nThe N-dimensional state space is projected into its first two dimensions.\nA FeatureInverter wrapper should be used to select which features to put first to plot them</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file where to plot the function</li>\n<li><strong>save_figure</strong>:  whether the plot should be saved into a file</li>\n<li><strong>stochastic</strong>:  whether we plot the deterministic or stochastic version</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    stochastic=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_any_env_critic_v", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_any_env_critic_v", "type": "function", "doc": "<p>Visualization of the critic in a N-dimensional state space\nThe N-dimensional state space is projected into its first two dimensions.\nA FeatureInverter wrapper should be used to select which features to put first to plot them</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file where to plot the function</li>\n<li><strong>save_figure</strong>:  whether the plot should be saved into a file</li>\n<li><strong>stochastic</strong>:  whether we plot the deterministic or stochastic version</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    stochastic=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_pendulum_critic_q", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_pendulum_critic_q", "type": "function", "doc": "<p>Plot a critic for the Pendulum environment</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the evaluation environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file to save the figure</li>\n<li><strong>save_figure</strong>:  whether the figure should be saved</li>\n<li><strong>action</strong>:  the action for which we want to plot the value</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    action=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_cartpole_critic_q", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_cartpole_critic_q", "type": "function", "doc": "<p>Visualization of the critic in a N-dimensional state space\nThe N-dimensional state space is projected into its first two dimensions.\nA FeatureInverter wrapper should be used to select which features to put first to plot them</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file where to plot the function</li>\n<li><strong>save_figure</strong>:  whether the plot should be saved into a file</li>\n<li><strong>action</strong>:  the action for which we want to plot the value</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    action=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_critics.plot_any_env_critic_q", "modulename": "bbrl.visu.visu_critics", "qualname": "plot_any_env_critic_q", "type": "function", "doc": "<p>Visualization of the critic in a N-dimensional state space\nThe N-dimensional state space is projected into its first two dimensions.\nA FeatureInverter wrapper should be used to select which features to put first to plot them</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the critic agent to be plotted</li>\n<li><strong>env</strong>:  the environment</li>\n<li><strong>env_string</strong>:  the name of the environment</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>directory</strong>:  the directory where to save the figure</li>\n<li><strong>figure_name</strong>:  the name of the file where to plot the function</li>\n<li><strong>save_figure</strong>:  whether the plot should be saved into a file</li>\n<li><strong>action</strong>:  the action for which we want to plot the value</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    env_string,\n    directory,\n    figure_name,\n    plot=True,\n    save_figure=True,\n    action=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_policies", "modulename": "bbrl.visu.visu_policies", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.visu.visu_policies.plot_policy", "modulename": "bbrl.visu.visu_policies", "qualname": "plot_policy", "type": "function", "doc": "<p></p>\n", "signature": "(\n    agent,\n    env,\n    directory,\n    env_name,\n    best_reward,\n    plot=False,\n    stochastic=False\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_policies.plot_pendulum_policy", "modulename": "bbrl.visu.visu_policies", "qualname": "plot_pendulum_policy", "type": "function", "doc": "<p>Plot an agent for the Pendulum environment</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the policy specifying the action to be plotted</li>\n<li><strong>env</strong>:  the evaluation environment</li>\n<li><strong>figname</strong>:  the name of the file to save the figure</li>\n<li><strong>directory</strong>:  the path to the file to save the figure</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>save_figure</strong>:  whether the figure should be saved</li>\n<li><strong>stochastic</strong>:  whether one wants to plot a deterministic or stochastic policy</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    directory,\n    figname,\n    plot=True,\n    save_figure=True,\n    stochastic=None\n)", "funcdef": "def"}, {"fullname": "bbrl.visu.visu_policies.plot_cartpole_policy", "modulename": "bbrl.visu.visu_policies", "qualname": "plot_cartpole_policy", "type": "function", "doc": "<p>Visualization of a policy in a N-dimensional state space\nThe N-dimensional state space is projected into its first two dimensions.\nA FeatureInverter wrapper should be used to select which features to put first to plot them</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>agent</strong>:  the policy agent to be plotted</li>\n<li><strong>env</strong>:  the environment</li>\n<li><strong>figname</strong>:  the name of the file to save the figure</li>\n<li><strong>directory</strong>:  the path to the file to save the figure</li>\n<li><strong>plot</strong>:  whether the plot should be interactive</li>\n<li><strong>save_figure</strong>:  whether the figure should be saved</li>\n<li><strong>stochastic</strong>:  whether one wants to plot a deterministic or stochastic policy</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>nothing</p>\n</blockquote>\n", "signature": "(\n    agent,\n    env,\n    directory,\n    figname,\n    plot=True,\n    save_figure=True,\n    stochastic=None\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace", "modulename": "bbrl.workspace", "type": "module", "doc": "<p></p>\n"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor", "type": "class", "doc": "<p>A SlicedTemporalTensor represents a tensor of size TxBx... by using a list of tensors of size Bx...\nThe interest is that this tensor automatically adapts its timestep dimension and does not need to have a predefined size.</p>\n"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.__init__", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.__init__", "type": "function", "doc": "<p>Initialize an empty tensor</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.set", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.set", "type": "function", "doc": "<p>Set a value (dim Bx...) at time t</p>\n", "signature": "(\n    self,\n    t: int,\n    value: torch.Tensor,\n    batch_dims: 'Optional[tuple[int, int]]'\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.to", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.to", "type": "function", "doc": "<p>Move the tensor to a specific device</p>\n", "signature": "(self, device: torch.device)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.get", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.get", "type": "function", "doc": "<p>Get the value of the tensor at time t</p>\n", "signature": "(self, t: int, batch_dims: 'Optional[tuple[int, int]]')", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.get_full", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.get_full", "type": "function", "doc": "<p>Returns the complete tensor of size TxBx...</p>\n", "signature": "(self, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.get_time_truncated", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.get_time_truncated", "type": "function", "doc": "<p>Returns tensor[from_time:to_time]</p>\n", "signature": "(\n    self,\n    from_time: int,\n    to_time: int,\n    batch_dims: 'Optional[tuple[int, int]]'\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.set_full", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.set_full", "type": "function", "doc": "<p>Set the tensor given a BxTx... tensor.\nThe input tensor is cut into slices that are stored in a list of tensors</p>\n", "signature": "(self, value: torch.Tensor, batch_dims: 'Optional[tuple[int, int]]')", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.time_size", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.time_size", "type": "function", "doc": "<p>Return the size of the time dimension</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.batch_size", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.batch_size", "type": "function", "doc": "<p>Return the size of the batch dimension</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.select_batch", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.select_batch", "type": "function", "doc": "<p>Return the tensor where the batch dimension has been selected by the index</p>\n", "signature": "(self, batch_indexes: torch.LongTensor)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.clear", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.clear", "type": "function", "doc": "<p>Clear the tensor</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.copy_time", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.copy_time", "type": "function", "doc": "<p>Copy temporal slices of the tensor from from_time:from_time+n_steps to to_time:to_time+n_steps</p>\n", "signature": "(self, from_time: int, to_time: int, n_steps: int)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.subtime", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.subtime", "type": "function", "doc": "<p>Return tensor[from_t:to_t]</p>\n", "signature": "(self, from_t: int, to_t: int)", "funcdef": "def"}, {"fullname": "bbrl.workspace.SlicedTemporalTensor.zero_grad", "modulename": "bbrl.workspace", "qualname": "SlicedTemporalTensor.zero_grad", "type": "function", "doc": "<p>Clear any gradient information in the tensor</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor", "type": "class", "doc": "<p>A CompactTemporalTensor is a tensor of size TxBx...\nIt behaves like the <code>SlicedTemporalTensor</code> but has a fixed size that cannot change.\nIt is faster than the SlicedTemporalTensor.\n    See <code>SlicedTemporalTensor</code></p>\n"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.__init__", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, value: torch.Tensor = None)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.set", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.set", "type": "function", "doc": "<p></p>\n", "signature": "(self, t, value, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.select_batch", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.select_batch", "type": "function", "doc": "<p></p>\n", "signature": "(self, batch_indexes)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.to_sliced", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.to_sliced", "type": "function", "doc": "<p>Transform the tensor to a <code>SlicedTemporalTensor</code></p>\n", "signature": "(self) -> bbrl.workspace.SlicedTemporalTensor", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.to", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.to", "type": "function", "doc": "<p></p>\n", "signature": "(self, device)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.get", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.get", "type": "function", "doc": "<p></p>\n", "signature": "(self, t, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.get_full", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.get_full", "type": "function", "doc": "<p></p>\n", "signature": "(self, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.time_size", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.time_size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.batch_size", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.batch_size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.set_full", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.set_full", "type": "function", "doc": "<p></p>\n", "signature": "(self, value, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.subtime", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.subtime", "type": "function", "doc": "<p></p>\n", "signature": "(self, from_t, to_t)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.clear", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.clear", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.copy_time", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.copy_time", "type": "function", "doc": "<p></p>\n", "signature": "(self, from_time, to_time, n_steps)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactTemporalTensor.zero_grad", "modulename": "bbrl.workspace", "qualname": "CompactTemporalTensor.zero_grad", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor", "type": "class", "doc": "<p>It corresponds to a tensor in shared memory.\nIt is used when building a workspace shared by multiple processes.\n    All the methods behaves like the methods of <code>SlicedTemporalTensor</code></p>\n"}, {"fullname": "bbrl.workspace.CompactSharedTensor.__init__", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, _tensor: torch.Tensor)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.set", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.set", "type": "function", "doc": "<p></p>\n", "signature": "(self, t, value, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.get", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.get", "type": "function", "doc": "<p></p>\n", "signature": "(self, t, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.to", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.to", "type": "function", "doc": "<p></p>\n", "signature": "(self, device)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.select_batch", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.select_batch", "type": "function", "doc": "<p></p>\n", "signature": "(self, batch_indexes)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.get_full", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.get_full", "type": "function", "doc": "<p></p>\n", "signature": "(self, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.time_size", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.time_size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.batch_size", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.batch_size", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.set_full", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.set_full", "type": "function", "doc": "<p></p>\n", "signature": "(self, value, batch_dims)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.clear", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.clear", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.subtime", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.subtime", "type": "function", "doc": "<p></p>\n", "signature": "(self, from_t, to_t)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.copy_time", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.copy_time", "type": "function", "doc": "<p></p>\n", "signature": "(self, from_time, to_time, n_steps)", "funcdef": "def"}, {"fullname": "bbrl.workspace.CompactSharedTensor.zero_grad", "modulename": "bbrl.workspace", "qualname": "CompactSharedTensor.zero_grad", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.take_per_row_strided", "modulename": "bbrl.workspace", "qualname": "take_per_row_strided", "type": "function", "doc": "<p></p>\n", "signature": "(a, index, num_elem=2)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace", "modulename": "bbrl.workspace", "qualname": "Workspace", "type": "class", "doc": "<p>Workspace is the most important class in <code>bbrl</code>.\nIt correponds to a collection of tensors\n('SlicedTemporalTensor<code>,</code>CompactTemporalTensor<code>or</code> CompactSharedTensor`).\nIn the majority of cases, we consider that all the tensors have the same time and batch sizes\n(but it is not mandatory for most of the functions)</p>\n"}, {"fullname": "bbrl.workspace.Workspace.__init__", "modulename": "bbrl.workspace", "qualname": "Workspace.__init__", "type": "function", "doc": "<p>Create an empty workspace</p>\n\n<p>Args:\n    workspace (Workspace, optional): If specified, it creates a copy of the workspace\n(where tensors are cloned as CompactTemporalTensors)</p>\n", "signature": "(self, workspace: Union[bbrl.workspace.Workspace, NoneType] = None)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.set", "modulename": "bbrl.workspace", "qualname": "Workspace.set", "type": "function", "doc": "<p>Set the variable var_name at time t</p>\n", "signature": "(\n    self,\n    var_name: str,\n    t: int,\n    v: torch.Tensor,\n    batch_dims: 'Optional[tuple[int, int]]' = None\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.get", "modulename": "bbrl.workspace", "qualname": "Workspace.get", "type": "function", "doc": "<p>Get the variable var_name at time t</p>\n", "signature": "(\n    self,\n    var_name: str,\n    t: int,\n    batch_dims: 'Optional[tuple[int, int]]' = None\n) -> torch.Tensor", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.clear", "modulename": "bbrl.workspace", "qualname": "Workspace.clear", "type": "function", "doc": "<p>Remove all the variables from the workspace</p>\n", "signature": "(self, name=None)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.contiguous", "modulename": "bbrl.workspace", "qualname": "Workspace.contiguous", "type": "function", "doc": "<p>Generates a workspace where all tensors are stored in the Compact format.</p>\n", "signature": "(self) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.set_full", "modulename": "bbrl.workspace", "qualname": "Workspace.set_full", "type": "function", "doc": "<p>Set variable var_name with a complete tensor (TxBx...) where T is the time dimension\nand B is the batch size</p>\n", "signature": "(\n    self,\n    var_name: str,\n    value: torch.Tensor,\n    batch_dims: 'Optional[tuple[int, int]]' = None\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.get_full", "modulename": "bbrl.workspace", "qualname": "Workspace.get_full", "type": "function", "doc": "<p>Return the complete tensor for var_name</p>\n", "signature": "(\n    self,\n    var_name: str,\n    batch_dims: 'Optional[tuple[int, int]]' = None\n) -> torch.Tensor", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.keys", "modulename": "bbrl.workspace", "qualname": "Workspace.keys", "type": "function", "doc": "<p>Return an iterator over the variables names</p>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.time_size", "modulename": "bbrl.workspace", "qualname": "Workspace.time_size", "type": "function", "doc": "<p>Return the time size of the variables in the workspace</p>\n", "signature": "(self) -> int", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.batch_size", "modulename": "bbrl.workspace", "qualname": "Workspace.batch_size", "type": "function", "doc": "<p>Return the batch size of the variables in the workspace</p>\n", "signature": "(self) -> int", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.select_batch", "modulename": "bbrl.workspace", "qualname": "Workspace.select_batch", "type": "function", "doc": "<p>Given a tensor of indexes, returns a new workspace\nwith the selected elements (over the batch dimension)</p>\n", "signature": "(self, batch_indexes: torch.LongTensor) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.select_batch_n", "modulename": "bbrl.workspace", "qualname": "Workspace.select_batch_n", "type": "function", "doc": "<p>Return a new Workspace of batch_size==n by randomly sampling over the batch dimensions</p>\n", "signature": "(self, n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.copy_time", "modulename": "bbrl.workspace", "qualname": "Workspace.copy_time", "type": "function", "doc": "<p>Copy all the variables values from time <code>from_time</code> to <code>from_time+n_steps</code>\nto <code>to_time</code> to <code>to_time+n_steps</code>\nIt can be restricted to specific variables using <code>var_names</code>.</p>\n", "signature": "(\n    self,\n    from_time: int,\n    to_time: int,\n    n_steps: int,\n    var_names: 'Optional[list[str]]' = None\n)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.get_time_truncated", "modulename": "bbrl.workspace", "qualname": "Workspace.get_time_truncated", "type": "function", "doc": "<p>Return workspace[var_name][from_time:to_time]</p>\n", "signature": "(\n    self,\n    var_name: str,\n    from_time: int,\n    to_time: int,\n    batch_dims: 'Optional[tuple[int, int]]' = None\n) -> torch.Tensor", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.get_time_truncated_workspace", "modulename": "bbrl.workspace", "qualname": "Workspace.get_time_truncated_workspace", "type": "function", "doc": "<p>Return a workspace where all variables are truncated between from_time and to_time</p>\n", "signature": "(self, from_time: int, to_time: int) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.cat_batch", "modulename": "bbrl.workspace", "qualname": "Workspace.cat_batch", "type": "function", "doc": "<p>Concatenate multiple workspaces over the batch dimension.\nThe workspaces must have the same time dimension.</p>\n", "signature": "(self, workspaces: 'list[Workspace]') -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.copy_n_last_steps", "modulename": "bbrl.workspace", "qualname": "Workspace.copy_n_last_steps", "type": "function", "doc": "<p>Copy the n last timesteps of each variable to the n first timesteps.</p>\n", "signature": "(self, n: int, var_names: 'Optional[list[str]]' = None) -> None", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.zero_grad", "modulename": "bbrl.workspace", "qualname": "Workspace.zero_grad", "type": "function", "doc": "<p>Remove any gradient information</p>\n", "signature": "(self) -> None", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.to", "modulename": "bbrl.workspace", "qualname": "Workspace.to", "type": "function", "doc": "<p>Return a workspace where all tensors are on a particular device</p>\n", "signature": "(self, device: torch.device) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.subtime", "modulename": "bbrl.workspace", "qualname": "Workspace.subtime", "type": "function", "doc": "<p>Return a workspace restricted to a subset of the time dimension</p>\n", "signature": "(self, from_t: int, to_t: int) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.remove_variable", "modulename": "bbrl.workspace", "qualname": "Workspace.remove_variable", "type": "function", "doc": "<p>Remove a variable from the Workspace</p>\n", "signature": "(self, var_name: str)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.select_subtime", "modulename": "bbrl.workspace", "qualname": "Workspace.select_subtime", "type": "function", "doc": "<p><code>t</code> is a tensor of size <code>batch_size</code> that provides one time index for each element of the workspace.\nThen the function returns a new workspace by aggregating <code>window_size</code> timesteps starting from index <code>t</code>\nThis methods allows to sample multiple windows in the Workspace.\nNote that the function may be quite slow.</p>\n", "signature": "(self, t: torch.LongTensor, window_size: int) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.sample_subworkspace", "modulename": "bbrl.workspace", "qualname": "Workspace.sample_subworkspace", "type": "function", "doc": "<p>Sample a workspace from the  workspace. The process is the following:\n        * Let us consider that workspace batch_size is B and time_size is T\n        * For n_times iterations:\n            * We sample a time window of size n_timesteps\n            * We then sample a n_batch_elements elements on the batch size\n            * =&gt;&gt; we obtain a worspace of size n_batch_elements x n_timesteps\n        * We concatenate all the workspaces collected (over the batch dimension)</p>\n\n<p>Args:\n    n_times ([type]): The number of sub workspaces to sample (and concatenate)\n    n_batch_elements ([type]): &lt;=workspace.batch_size(): nb of batch elements to sample for each subworkspace\n    n_timesteps ([type]): &lt;=workspace.time_size(): the number of timesteps to keep</p>\n\n<p>Returns:\n    [Workspace]: The resulting workspace</p>\n", "signature": "(self, n_times, n_batch_elements, n_timesteps)", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.get_transitions", "modulename": "bbrl.workspace", "qualname": "Workspace.get_transitions", "type": "function", "doc": "<p>Takes in a workspace from salina:\n[(step1),(step2),(step3), ... ]\nreturn a workspace of transitions :\n[\n    [step1,step2],\n    [step2,step3]\n    ...\n]\nFilters every transitions [step_final,step_initial]</p>\n", "signature": "(self) -> bbrl.workspace.Workspace", "funcdef": "def"}, {"fullname": "bbrl.workspace.Workspace.debug_transitions", "modulename": "bbrl.workspace", "qualname": "Workspace.debug_transitions", "type": "function", "doc": "<p></p>\n", "signature": "(self, truncated)", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();